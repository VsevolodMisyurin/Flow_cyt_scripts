{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d424f8b7-0621-4c48-8bf2-b6889047e8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fcsparser import parse\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import umap\n",
    "import time\n",
    "from scipy.stats import norm\n",
    "from transliterate import translit\n",
    "import warnings\n",
    "import pickle\n",
    "from matplotlib.patches import Polygon\n",
    "from openpyxl import load_workbook\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from scipy.interpolate import griddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd3b4cc-f621-49d1-bf90-ef4b99bd985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "–í–µ—Ä–∏—Å–∏—è 10, —Å—Ç–∞–±–∏–ª—å–Ω–∞—è\n",
    "–û–±–Ω–æ–≤–ª—ë–Ω –≥–µ–π—Ç –¥–ª—è –≥—Ä–∞–Ω—É–ª–æ—Ü–∏—Ç–æ–≤.\n",
    "–î–æ–±–∞–≤–∏–ª –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞.\n",
    "–ë–æ–ª—å—à–µ —ç–ø–æ—Ö - –¥–∞–ª—å—à–µ —Ä–∞—Å—Ö–æ–¥—è—Ç—Å—è –∫–ª–∞—Å—Ç–µ—Ä—ã, –Ω–æ –Ω—É–∂–Ω–æ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –≥–µ–π—Ç—ã.\n",
    "–î–æ–±–∞–≤–∏–ª –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø–µ—Ä–µ–Ω–æ—Å–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ .csv –≤ —Ñ–∞–π–ª –∑–∞–∫–ª—é—á–µ–Ω–∏—è.\n",
    "–ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –¥–ª—è –ø–µ—Ä–µ–Ω–æ—Å–∞ –¥–∞–Ω–Ω—ã—Ö —Ç–æ–∂–µ —Å—Ç–∞–≤—è—Ç—Å—è –≤—Ä—É—á–Ω—É—é.\n",
    "\n",
    "–í–µ—Ä—Å–∏—è 9, —Å—Ç–∞–±–∏–ª—å–Ω–∞\n",
    "–ò—Å–ø—Ä–∞–≤–ª–µ–Ω –≥–µ–π—Ç –¥–ª—è –º—É—Å–æ—Ä–∞. –î–æ–±–∞–≤–ª–µ–Ω—ã –≥–µ–π—Ç—ã –¥–ª—è CD117, –Ω–æ –Ω—É–∂–Ω–æ –¥–æ—Ä–∞–±–æ—Ç–∞—Ç—å\n",
    "–ù–µ—É–¥–∞—á–Ω–æ –ø—Ä–æ–≤–µ–¥—ë–Ω –ø–æ–∏—Å–∫ –≥–µ–π—Ç–æ–≤ –¥–ª—è –∫–∞–ø–ø–∞ –∏ –ª—è–º–±–¥–∞.\n",
    "\n",
    "–í–µ—Ä—Å–∏—è 8 - —Ä–µ—à–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã —Å —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å—é. –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–æ–±–∞–≤–∏—Ç—å –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ \n",
    "–≤–µ—Ä—Å–∏–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫.–° –¥–∞–Ω–Ω—ã–º–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞–º–∏ –ø–æ–ø—É–ª—è—Ü–∏–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞—é—Ç—Å—è –æ–¥–∏–Ω–∞–∫–æ–≤–æ.\n",
    "\n",
    "–í–µ—Ä—Å–∏—è 7 - –ì–æ—Ç–æ–≤ —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞ –¥–∞–Ω–Ω—ã—Ö, –æ–±—É—á–µ–Ω–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è \n",
    "–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤,–∑–∞–≥—Ä—É–∑–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, —Ä–∞–∑–º–µ—Ç–∫–∏ –ø–æ–ø—É–ª—è—Ü–∏–π –Ω–∞ —é–º–∞–ø, \n",
    "–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —é–º–∞–ø –∫ —Ç–µ—Å—Ç–æ–≤—ã–º –¥–∞–Ω–Ω—ã–º\n",
    "\n",
    "–ù–µ–æ–±—Ö–æ–¥–∏–º–æ:–ó–∞–≤–µ—Ä—à–∏—Ç—å —Ä–∞–∑–º–µ—Ç–∫—Éprocess_test_data —Ñ—É–Ω–∫—Ü–∏—é –¥–æ—Ä–∞–±–æ—Ç–∞—Ç—å –¥–æ –≤—ã–¥–∞—á–∏ \n",
    "–∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π —ç–∫—Å–ø—Ä–µ—Å—Å–∏–∏ –∞–Ω—Ç–∏–≥–µ–Ω–æ–≤ –∑–∞ –≤—ã—á–µ—Ç–æ–º –º—É—Å–æ—Ä–∞–°–æ—Å—Ç–∞–≤–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è \n",
    "—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç—á—ë—Ç–∞ –∏ –∑–∞–Ω–µ—Å–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –≤ excel-–±–ª–∞–Ω–∫–∏–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –±—É–¥–µ—Ç –ª–∏ –ø—Ä–∏–º–µ–Ω—è—Ç—å \n",
    "process_test_data –Ω—É–∂–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∫ –ø—Ä–æ–±–∏—Ä–∫–µ —Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º –Ω–∞–∑–≤–∞–Ω–∏–µ–º. \n",
    "–ü–æ –∏–¥–µ–µ, –¥–æ–ª–∂–µ–Ω–í—ã–Ω–µ—Å—Ç–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–µ—Å—Ç–æ–º –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª\n",
    "–£–ø–∞–∫–æ–≤–∞—Ç—å –≤ –¥–æ–∫–µ—Ä –∏–ª–∏ —Ö–æ—Ç—è –±—ã .py-—Å–∫—Ä–∏–ø—Ç –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∑–∞–ø—É—Å–∫–∞\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cae190-031a-4d65-85a5-ef53f2dbd1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = r\"C:\\Users\\vsemis\\files\\Flow_cyt_robot\" # –≤–Ω–∏–º–∞–Ω–∏–µ –∫–æ–º–ø\n",
    "path = r\"D:\\NovoExpress Data\"  # –æ—á–µ—Ä–µ–¥–Ω–æ–π –∫–æ–º–ø"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae6939c-5b8d-4e7a-9519-0c09e38a6556",
   "metadata": {},
   "source": [
    "# –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e9883d-d67e-4cd9-8a13-d9e37e2f76c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transp_znorm_data(data):\n",
    "    \"\"\"\n",
    "    –í—ã–ø–æ–ª–Ω—è–µ—Ç –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å —Å–æ–±—ã—Ç–∏—è–º–∏\n",
    "    –ü–æ—Å–ª–µ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —Ç—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ z-–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è,\n",
    "    –ø–æ—Å–ª–µ —á–µ–≥–æ - –ø–æ–≤—Ç–æ—Ä–Ω–æ–µ —Ç—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞\n",
    "    –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —ç—Ç–∏—Ö –¥–µ–π—Å—Ç–≤–∏–π –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∞ –ø—Ä–µ–¥—à–µ—Å—Ç–≤—É—é—â–∏–º–∏ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è–º–∏\n",
    "    \"\"\"\n",
    "    data_clipped = data.clip(lower=1)  # –ö–ª–∏–ø—É–µ–º –¥–∞–Ω–Ω—ã–µ, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å log(0)\n",
    "    data_log = data_clipped.apply(np.log2)  # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "    data_log = data_log.T  # –¢—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "    data_log_transp_znorm = (data_log - data_log.mean()) / data_log.std()  # z-–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "    data_log_transp_znorm = data_log_transp_znorm.T  # –¢—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "    \n",
    "    return data_log_transp_znorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1663525f-a098-4009-9f96-af47dab987ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_percentile(df, columns=None, lower_quantile=0.0025, upper_quantile=0.99):\n",
    "    \"\"\"\n",
    "    –£–¥–∞–ª—è–µ—Ç –≤—ã–±—Ä–æ—Å—ã –≤ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–µ df, –æ–±—Ä–µ–∑–∞—è –∑–Ω–∞—á–µ–Ω–∏—è –∑–∞ –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—è–º–∏.\n",
    "    \n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        –ò—Å—Ö–æ–¥–Ω—ã–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º.\n",
    "    columns : list or None\n",
    "        –°–ø–∏—Å–æ–∫ —Å—Ç–æ–ª–±—Ü–æ–≤, –ø–æ –∫–æ—Ç–æ—Ä—ã–º –∏—â–µ–º –≤—ã–±—Ä–æ—Å—ã.\n",
    "        –ï—Å–ª–∏ None, —Ç–æ –±–µ—Ä—ë–º –≤—Å–µ —á–∏—Å–ª–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã.\n",
    "    lower_quantile : float\n",
    "        –ù–∏–∂–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞ (–æ—Ç 0 –¥–æ 1), –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.0025 (0.25%).\n",
    "    upper_quantile : float\n",
    "        –í–µ—Ä—Ö–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞ (–æ—Ç 0 –¥–æ 1), –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.99 (99%).\n",
    "    \n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:\n",
    "    -----------\n",
    "    pd.DataFrame\n",
    "        –î–∞—Ç–∞—Ñ—Ä–µ–π–º –±–µ–∑ –≤—ã–±—Ä–æ—Å–æ–≤.\n",
    "    \"\"\"\n",
    "    \n",
    "    # –ï—Å–ª–∏ —Å—Ç–æ–ª–±—Ü—ã –Ω–µ —É–∫–∞–∑–∞–Ω—ã, –±–µ—Ä—ë–º –≤—Å–µ —á–∏—Å–ª–æ–≤—ã–µ\n",
    "    if columns is None:\n",
    "        columns = df.select_dtypes(include='number').columns.tolist()\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–¥–∏–º –∫–æ–ø–∏—é, —á—Ç–æ–±—ã –Ω–µ –º–µ–Ω—è—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    for col in columns:\n",
    "        if col not in df_clean.columns:\n",
    "            # –ï—Å–ª–∏ –≤ —Å–ø–∏—Å–∫–µ –æ–∫–∞–∑–∞–ª—Å—è —Å—Ç–æ–ª–±–µ—Ü, –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–µ—Ç –≤ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–µ\n",
    "            continue\n",
    "        \n",
    "        # –í—ã—á–∏—Å–ª–∏–º –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª–∏\n",
    "        low_val = df_clean[col].quantile(lower_quantile)\n",
    "        high_val = df_clean[col].quantile(upper_quantile)\n",
    "        \n",
    "        # –§–∏–ª—å—Ç—Ä—É–µ–º –≤—ã–±—Ä–æ—Å—ã\n",
    "        df_clean = df_clean[(df_clean[col] >= low_val) & (df_clean[col] <= high_val)]\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdf6f22-2434-44a1-b870-816fbada98fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_arcsinh_transform_data(data, cofactor_mapping=None):  # –ò—Å–ø—Ä–∞–≤–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ!!!\n",
    "    \"\"\"\n",
    "    –ü—Ä–∏–º–µ–Ω—è–µ—Ç –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –∫ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º—É.\n",
    "    \n",
    "    –î–ª—è —Å—Ç–æ–ª–±—Ü–æ–≤, –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ –∫–æ—Ç–æ—Ä—ã—Ö –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –æ–¥–Ω–æ –∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ \n",
    "    ('CD'), –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è arcsinh-–ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å –∑–∞–¥–∞–Ω–Ω—ã–º –∫–æ-—Ñ–∞–∫—Ç–æ—Ä–æ–º.\n",
    "    –î–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∫–ª–∏–ø–ø–∏–Ω–≥ (—á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å log(0)) –∏ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏–µ.\n",
    "    \n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        –ò—Å—Ö–æ–¥–Ω—ã–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º.\n",
    "    cofactor_mapping : dict, optional\n",
    "        –°–ª–æ–≤–∞—Ä—å, —Å–æ–ø–æ—Å—Ç–∞–≤–ª—è—é—â–∏–π –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏ –∏—Ö –∫–æ-—Ñ–∞–∫—Ç–æ—Ä—ã.\n",
    "        –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: {'CD': 5}\n",
    "    \n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:\n",
    "    -----------\n",
    "    pd.DataFrame\n",
    "        –î–∞—Ç–∞—Ñ—Ä–µ–π–º –ø–æ—Å–ª–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π.\n",
    "    \"\"\"\n",
    "    if cofactor_mapping is None:\n",
    "        cofactor_mapping = {'CD': 3, 'Ig': 3}  # —Ö–æ—Ä–æ—à–∏–µ: 5\n",
    "    \n",
    "    data_transformed = data.copy()\n",
    "    \n",
    "    for col in data_transformed.columns:\n",
    "        # –ï—Å–ª–∏ –∏–º—è —Å—Ç–æ–ª–±—Ü–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–¥–Ω–æ –∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤,\n",
    "        # –ø—Ä–∏–º–µ–Ω—è–µ–º arcsinh-–ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º –∫–æ-—Ñ–∞–∫—Ç–æ—Ä–æ–º.\n",
    "        applied_arcsinh = False\n",
    "        for key, cofactor in cofactor_mapping.items():\n",
    "            if key in col:\n",
    "                data_transformed[col] = np.arcsinh(data_transformed[col] / cofactor)\n",
    "                applied_arcsinh = True\n",
    "                break  # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ, –¥–∞–ª—å–Ω–µ–π—à–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–µ —Ç—Ä–µ–±—É—é—Ç—Å—è.\n",
    "                \n",
    "        # –ï—Å–ª–∏ —Å—Ç–æ–ª–±–µ—Ü –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–∞–¥–∞–Ω–Ω—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤, –ø—Ä–∏–º–µ–Ω—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ:\n",
    "        if not applied_arcsinh:\n",
    "            # –ö–ª–∏–ø–ø–∏–Ω–≥ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è log(0)\n",
    "            data_transformed[col] = data_transformed[col].clip(lower=1)\n",
    "            # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ –æ—Å–Ω–æ–≤–∞–Ω–∏—é 2\n",
    "            data_transformed[col] = np.log2(data_transformed[col])\n",
    "            \n",
    "    return data_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5638abf9-03e0-42dd-aba6-88e0398534a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_umap_data_organiser(dirs, tube_list, size=10000, random_state=42):\n",
    "    \"\"\"\n",
    "    –î–∞–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–æ—Ö–æ–¥–∏—Ç –ø–æ —É–∫–∞–∑–∞–Ω–Ω—ã–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º, –∏—â–µ—Ç —Ñ–∞–π–ª—ã, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ\n",
    "    –∏–º–µ–Ω–∞–º –∏–∑ tube_list, –∑–∞–≥—Ä—É–∂–∞–µ—Ç –∏—Ö, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã \n",
    "    —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º train_data_<–∏–º—è —Ñ–∞–π–ª–∞>.csv –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è .fcs.\n",
    "    \"\"\"\n",
    "    for tube in tube_list:  # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –∫–∞–∂–¥–æ–º—É —Ñ–∞–π–ª—É –∏–∑ —Å–ø–∏—Å–∫–∞\n",
    "        combined_data = pd.DataFrame()  # –°–æ–∑–¥–∞—ë–º –ø—É—Å—Ç–æ–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º\n",
    "\n",
    "        for folder in dirs:\n",
    "            print(f\"\\nüìÇ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≥–ª–∞–≤–Ω—É—é –ø–∞–ø–∫—É: {folder}\")\n",
    "\n",
    "            for subfolder in os.listdir(folder):  # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –ø–æ–¥–ø–∞–ø–∫–∞–º\n",
    "                subfolder_path = os.path.join(folder, subfolder)\n",
    "                if os.path.isdir(subfolder_path):\n",
    "                    print(f\"   üìÅ –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –ø–∞–ø–∫–∞: {subfolder}\")\n",
    "\n",
    "                    for file in os.listdir(subfolder_path):\n",
    "                        if file == tube:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ –∏–º—è —Ñ–∞–π–ª–∞ —Ç–µ–∫—É—â–µ–º—É tube\n",
    "                            file_path = os.path.join(subfolder_path, file)\n",
    "                            print(f\"      üìÑ –ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª: {file}\")\n",
    "\n",
    "                            meta, data = parse(file_path)\n",
    "                            del meta  # –ù–µ –Ω—É–∂–Ω–æ, —É–¥–∞–ª—è–µ–º\n",
    "\n",
    "                            if len(data) > size:\n",
    "                                data = data.sample(n=size, random_state=random_state)  # –ë–µ—Ä—ë–º –Ω—É–∂–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫\n",
    "                            \n",
    "                            # –£–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã\n",
    "                            data = data.drop(columns=[col for col in data.columns if col.endswith(('-A', 'Width', 'Time'))])\n",
    "\n",
    "                            # –£–¥–∞–ª—è–µ–º –≤—ã–±—Ä–æ—Å—ã\n",
    "                            data = remove_outliers_percentile(data, columns=['FSC-H', 'SSC-H'])\n",
    "                            \n",
    "                            # –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é\n",
    "                            data = log_arcsinh_transform_data(data)  # –¶–∏—Ç–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥\n",
    "                            # data = (data - data.mean()) / data.std()  # z-–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "                            \n",
    "                            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–∏–ø–µ –æ–±—Ä–∞–∑—Ü–∞\n",
    "                            data[\"sample_type\"] = os.path.basename(folder)\n",
    "\n",
    "                            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É 'sample_name' —Å —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –Ω–∞–∑–≤–∞–Ω–∏–µ–º subfolder\n",
    "                            data[\"sample_name\"] = translit(subfolder, reversed=True)\n",
    "\n",
    "                            # –ï—Å–ª–∏ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –ø—É—Å—Ç, –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏\n",
    "                            if combined_data.empty:\n",
    "                                combined_data = pd.DataFrame(columns=data.columns)\n",
    "\n",
    "                            # –ü—Ä–∏—Å–æ–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "                            combined_data = pd.concat([combined_data, data], ignore_index=True)\n",
    "\n",
    "        if not combined_data.empty:\n",
    "            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–∞–ø–∫—É –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–Ω–∞ —É—Ä–æ–≤–µ–Ω—å –≤—ã—à–µ –ø–µ—Ä–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –≤ dirs)\n",
    "            base_output_dir = os.path.dirname(dirs[0])\n",
    "            output_dir = os.path.join(base_output_dir, \"train_data\")  # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞–ø–∫—É train_data\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "                print(f\"‚úÖ –ü–∞–ø–∫–∞ {output_dir} —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞!\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è –ü–∞–ø–∫–∞ {output_dir} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.\")\n",
    "            # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ (—É–±–∏—Ä–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ .fcs)\n",
    "            output_filename = f\"train_data_{os.path.splitext(tube)[0]}.csv\"\n",
    "            output_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "            combined_data.to_csv(output_path, index=False)\n",
    "            print(f\"\\n‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_path}\")\n",
    "        else:\n",
    "            print(f\"\\n‚ö†Ô∏è –§–∞–π–ª {tube} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è—Ö.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b135f09-1207-45a0-a291-3d111759e554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∏ –æ–±—É—á–µ–Ω–∏—è UMAP\n",
    "def plot_umap_from_dataframe(data, n_neighbors=20, min_dist=0.1, spread=5, metric=\"manhattan\", n_epochs=None):\n",
    "    \"\"\"\n",
    "    –í—ã–ø–æ–ª–Ω—è–µ—Ç UMAP –¥–ª—è –ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–≥–æ DataFrame –∏ —Å—Ç—Ä–æ–∏—Ç UMAP-–º–∞–ø.\n",
    "\n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): –ò—Å—Ö–æ–¥–Ω—ã–π DataFrame (–º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –Ω–µ—á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ).\n",
    "    - n_neighbors (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Å–µ–¥–µ–π –¥–ª—è UMAP.\n",
    "    - min_dist (float): –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É —Ç–æ—á–∫–∞–º–∏ –Ω–∞ –∫–∞—Ä—Ç–µ.\n",
    "    - spread (float): –ü–∞—Ä–∞–º–µ—Ç—Ä, –≤–ª–∏—è—é—â–∏–π –Ω–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏.\n",
    "    - metric (str): –ú–µ—Ç—Ä–∏–∫–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é \"manhattan\").\n",
    "    - n_epochs (int, optional): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –¥–ª—è UMAP (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∞–≤—Ç–æ).\n",
    "\n",
    "    Returns:\n",
    "    - umap_df (pd.DataFrame): DataFrame —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏ UMAP.\n",
    "    - reducer (umap.UMAP): –û–±—É—á–µ–Ω–Ω—ã–π UMAP-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä.\n",
    "    \"\"\"\n",
    "\n",
    "    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã\n",
    "    numeric_data = data.select_dtypes(include=[np.number])\n",
    "\n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –æ—Å—Ç–∞–ª–∏—Å—å —á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
    "    if numeric_data.empty:\n",
    "        raise ValueError(\"–ü–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –Ω–µ—á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ DataFrame –æ–∫–∞–∑–∞–ª—Å—è –ø—É—Å—Ç—ã–º!\")\n",
    "\n",
    "    # –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", message=\".*n_jobs value 1 overridden.*\")\n",
    "\n",
    "        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ –æ–±—É—á–µ–Ω–∏–µ UMAP\n",
    "        reducer = umap.UMAP(\n",
    "            n_components=2,\n",
    "            n_neighbors=n_neighbors,\n",
    "            random_state=42,\n",
    "            min_dist=min_dist,\n",
    "            spread=spread,\n",
    "            metric=metric,\n",
    "            n_epochs=n_epochs,  # <-- –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫—É —ç–ø–æ—Ö\n",
    "            verbose=True  # <-- –î–ª—è –ª–æ–≥–æ–≤ –æ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—É—á–µ–Ω–∏—è\n",
    "        )\n",
    "        umap_result = reducer.fit_transform(numeric_data)\n",
    "\n",
    "    # –°–æ–∑–¥–∞—ë–º DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ UMAP\n",
    "    umap_df = pd.DataFrame(umap_result, columns=['UMAP1', 'UMAP2'])\n",
    "\n",
    "    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(umap_df['UMAP1'], umap_df['UMAP2'], alpha=0.6, s=10)\n",
    "    plt.title(f'UMAP Map (metric={metric}, n_epochs={n_epochs})')\n",
    "    plt.xlabel('UMAP Component 1')\n",
    "    plt.ylabel('UMAP Component 2')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return umap_df, reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3483e72c-fb16-485f-8bfe-13fabb1de81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è UMAP –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —á–∞—Ä—Ç–∞, –∞ —Ç–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ UMAP –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞\n",
    "# –û–±—Ä–∞—â–∞–µ—Ç—Å—è –∫ –ø—Ä–µ–¥—à–µ—Å—Ç–≤—É—é—â–µ–π —Ñ—É–Ω–∫—Ü–∏–∏\n",
    "def process_and_save_umap(dirs, tube, n_neighbors=25, min_dist=0.001, spread=1, metric=\"manhattan\", n_epochs=None):\n",
    "\n",
    "    \"\"\"\n",
    "    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ—Ö–æ–¥–∏—Ç –ø–æ —Ñ–∞–π–ª–∞–º –≤ train_data, —Å—Ç—Ä–æ–∏—Ç UMAP –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ Saved_UMAP_n_csv.\n",
    "\n",
    "    Parameters:\n",
    "    - dirs (list): –°–ø–∏—Å–æ–∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π (–∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–ª—è –ø–æ–∏—Å–∫–∞ Examples).\n",
    "    - tube (list): –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤, —Å –∫–æ—Ç–æ—Ä—ã–º–∏ —Ä–∞–±–æ—Ç–∞–ª–∏ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏).\n",
    "    - n_neighbors, min_dist, spread, metric: –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è UMAP.\n",
    "    - n_epochs (int, optional): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –¥–ª—è UMAP (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∞–≤—Ç–æ).\n",
    "    - parallel (bool): –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è.\n",
    "    \"\"\"\n",
    "\n",
    "    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –±–∞–∑–æ–≤—É—é –ø–∞–ø–∫—É \"Examples\"\n",
    "    examples_folder = os.path.dirname(dirs[0])  # –ü–æ–¥–Ω–∏–º–∞–µ–º—Å—è –Ω–∞ —É—Ä–æ–≤–µ–Ω—å –≤–≤–µ—Ä—Ö\n",
    "    train_data_folder = os.path.join(examples_folder, \"train_data\")\n",
    "    save_folder = os.path.join(examples_folder, \"Saved_UMAP_n_csv\")\n",
    "\n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ train_data\n",
    "    if not os.path.exists(train_data_folder):\n",
    "        print(f\"–û—à–∏–±–∫–∞: –ü–∞–ø–∫–∞ {train_data_folder} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!\")\n",
    "        return  \n",
    "\n",
    "    # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ CSV-—Ñ–∞–π–ª–æ–≤ –≤ train_data\n",
    "    files = [f for f in os.listdir(train_data_folder) if f.endswith(\".csv\")]\n",
    "    if not files:\n",
    "        print(\"–í –ø–∞–ø–∫–µ train_data –Ω–µ—Ç CSV-—Ñ–∞–π–ª–æ–≤!\")\n",
    "        return\n",
    "\n",
    "    # –ü—Ä–æ—Ö–æ–¥–∏–º —Ç–æ–ª—å–∫–æ –ø–æ —Ñ–∞–π–ª–∞–º, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç tube\n",
    "    for file in files:\n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –∫ tube (–ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –±–µ–∑ train_data_)\n",
    "        file_base_name = file.replace(\"train_data_\", \"\").replace(\".csv\", \"\")\n",
    "        if not any(tube_name.startswith(file_base_name) for tube_name in tube):\n",
    "            print(f\"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª {file}, —Ç–∞–∫ –∫–∞–∫ –æ–Ω –Ω–µ –≤ tube.\")\n",
    "            continue  \n",
    "\n",
    "        file_path = os.path.join(train_data_folder, file)\n",
    "        print(f\"\\n–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª: {file}\")\n",
    "\n",
    "        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # –°—Ç—Ä–æ–∏–º UMAP\n",
    "        umap_df, reducer = plot_umap_from_dataframe(\n",
    "            df,\n",
    "            n_neighbors=n_neighbors,\n",
    "            min_dist=min_dist,\n",
    "            spread=spread,\n",
    "            metric=metric,\n",
    "            n_epochs=n_epochs,  # <-- –ü–µ—Ä–µ–¥–∞—ë–º epochs\n",
    "        )\n",
    "\n",
    "        # –°–æ–∑–¥–∞—ë–º –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è\n",
    "        base_name = os.path.splitext(file)[0]  # –£–±–∏—Ä–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ .csv\n",
    "        df_umap_filename = f\"{base_name}_umap.csv\"\n",
    "        reducer_filename = f\"reducer_{base_name}.pkl\"\n",
    "\n",
    "        # –ü–æ–ª–Ω—ã–µ –ø—É—Ç–∏\n",
    "        df_umap_path = os.path.join(save_folder, df_umap_filename)\n",
    "        reducer_path = os.path.join(save_folder, reducer_filename)\n",
    "\n",
    "        # –û–±—ä–µ–¥–∏–Ω—è–µ–º df –∏ umap_df\n",
    "        df_umap = pd.concat([df, umap_df], axis=1)\n",
    "\n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "        df_umap.to_csv(df_umap_path, index=False)  \n",
    "\n",
    "        with open(reducer_path, \"wb\") as f:\n",
    "            pickle.dump(reducer, f)\n",
    "\n",
    "        print(f\"–î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:\\n - {df_umap_path}\\n - {reducer_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6d0a9e-ac9c-4eb8-a0ff-05565c4fea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –æ–±—É—á–µ–Ω–Ω–æ–≥–æ UMAP\n",
    "def fit_trained_umap(reducer, new_data):\n",
    "    \"\"\"\n",
    "    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–±—É—á–µ–Ω–Ω—ã–π UMAP –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∫ –Ω–æ–≤–æ–º—É –Ω–∞–±–æ—Ä—É –¥–∞–Ω–Ω—ã—Ö.\n",
    "    \n",
    "    Parameters:\n",
    "    - reducer (umap.UMAP): –û–±—É—á–µ–Ω–Ω—ã–π UMAP-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä.\n",
    "    - new_data (pd.DataFrame): –ù–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è UMAP.\n",
    "    \n",
    "    Returns:\n",
    "    - umap_df (pd.DataFrame): DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ UMAP –¥–ª—è –Ω–æ–≤–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö.\n",
    "    \"\"\"\n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ —è–≤–ª—è—é—Ç—Å—è —á–∏—Å–ª–æ–≤—ã–º–∏\n",
    "    if not all(new_data.dtypes.apply(lambda x: np.issubdtype(x, np.number))):\n",
    "        raise ValueError(\"–í—Å–µ —Å—Ç–æ–ª–±—Ü—ã –≤ DataFrame –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —á–∏—Å–ª–æ–≤—ã–º–∏.\")\n",
    "    \n",
    "    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–≥–æ UMAP\n",
    "    umap_result = reducer.transform(new_data)\n",
    "\n",
    "    # –°–æ–∑–¥–∞–Ω–∏–µ DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏\n",
    "    umap_df = pd.DataFrame(umap_result, columns=[f'UMAP{i+1}' for i in range(reducer.n_components)])\n",
    "\n",
    "    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ UMAP-–º–∞–ø–∞\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    if reducer.n_components >= 2:\n",
    "        plt.scatter(umap_df['UMAP1'], umap_df['UMAP2'], alpha=0.6, s=10)\n",
    "        plt.title('UMAP Map (New Data)')\n",
    "        plt.xlabel('UMAP Component 1')\n",
    "        plt.ylabel('UMAP Component 2')\n",
    "    else:\n",
    "        plt.scatter(range(len(umap_df)), umap_df['UMAP1'], alpha=0.6, s=10)\n",
    "        plt.title('UMAP Map (1D Projection)')\n",
    "        plt.xlabel('Samples')\n",
    "        plt.ylabel('UMAP Component 1')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return umap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4424e49d-d885-4e48-b6ab-117c45414947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_validation_data(dirs, tube):\n",
    "    \"\"\"\n",
    "    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ .fcs —Ñ–∞–π–ª–æ–≤, –ø—Ä–∏–º–µ–Ω—è–µ—Ç –∫ –Ω–∏–º —Ñ—É–Ω–∫—Ü–∏–∏ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏,\n",
    "    –∑–∞–≥—Ä—É–∂–∞–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π UMAP-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∏ —Å—Ç—Ä–æ–∏—Ç UMAP-—á–∞—Ä—Ç —Å –ø–æ–¥–ø–∏—Å—å—é ‚Äì –Ω–∞–∑–≤–∞–Ω–∏–µ–º —Ñ–∞–π–ª–∞.\n",
    "    \n",
    "    Parameters:\n",
    "    - dirs (list of str): –°–ø–∏—Å–æ–∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π, –≤ –∫–æ—Ç–æ—Ä—ã—Ö –Ω–∞—Ö–æ–¥—è—Ç—Å—è –ø–∞–ø–∫–∏ —Å –¥–∞–Ω–Ω—ã–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–∞–ø–∫–∞ MM_subpopulations).\n",
    "    - tube (list of str): –°–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –Ω–∞–∑–≤–∞–Ω–∏—è—Ö —Ñ–∞–π–ª–æ–≤ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ—Ñ–∏–∫—Å –¥–æ –ø–µ—Ä–≤–æ–π —Ç–æ—á–∫–∏).\n",
    "    \n",
    "    –†–µ–∑—É–ª—å—Ç–∞—Ç:\n",
    "    –î–ª—è –∫–∞–∂–¥–æ–≥–æ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ .fcs —Ñ–∞–π–ª–∞, —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—è—é—â–µ–≥–æ —É—Å–ª–æ–≤–∏—é, —Å—Ç—Ä–æ–∏—Ç—Å—è UMAP-—á–∞—Ä—Ç,\n",
    "    –ø–æ–¥–ø–∏—Å–∞–Ω–Ω—ã–π –Ω–∞–∑–≤–∞–Ω–∏–µ–º –¥–∞–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞.\n",
    "    \"\"\"\n",
    "    # –î–ª—è –∫–∞–∂–¥–æ–≥–æ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –ø—É—Ç–∏ –≤ —Å–ø–∏—Å–∫–µ dirs\n",
    "    for base_dir in dirs:\n",
    "        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –ø–∞–ø–æ–∫ –≤–Ω—É—Ç—Ä–∏ base_dir\n",
    "        for folder in os.listdir(base_dir):\n",
    "            folder_path = os.path.join(base_dir, folder)\n",
    "            if not os.path.isdir(folder_path):\n",
    "                continue\n",
    "            # –°–æ—Ö—Ä–∞–Ω–∏–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–∫—É—â–µ–π –ø–∞–ø–∫–∏ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏–ª–∏ –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏)\n",
    "            current_folder_name = folder  \n",
    "            # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º —Ñ–∞–π–ª–∞–º –≤ —Ç–µ–∫—É—â–µ–π –ø–∞–ø–∫–µ\n",
    "            for filename in os.listdir(folder_path):\n",
    "                if not filename.endswith(\".fcs\"):\n",
    "                    continue\n",
    "                # –î–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –∏–∑ tube, —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å—ã (–¥–æ –ø–µ—Ä–≤–æ–π —Ç–æ—á–∫–∏)\n",
    "                for tube_item in tube:\n",
    "                    tube_prefix = tube_item.split('.')[0]\n",
    "                    if tube_prefix in filename:\n",
    "                        # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, —Ñ–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É\n",
    "                        file_path = os.path.join(folder_path, filename)\n",
    "                        try:\n",
    "                            # –û—Ç–∫—Ä—ã–≤–∞–µ–º .fcs —Ñ–∞–π–ª —Å –ø–æ–º–æ—â—å—é fcsparser\n",
    "                            meta, data = parse(file_path)\n",
    "                            del meta  # –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω—É–∂–Ω—ã, —É–¥–∞–ª—è–µ–º\n",
    "                        except Exception as e:\n",
    "                            print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ —Ñ–∞–π–ª–∞ {file_path}: {e}\")\n",
    "                            continue\n",
    "                        \n",
    "                        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é —É–¥–∞–ª–µ–Ω–∏—è –≤—ã–±—Ä–æ—Å–æ–≤\n",
    "                        try:\n",
    "                            data_no_outliers = remove_outliers_percentile(data, \n",
    "                                                                          columns=None, \n",
    "                                                                          lower_quantile=0.0025, \n",
    "                                                                          upper_quantile=0.99)\n",
    "                        except Exception as e:\n",
    "                            print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –≤—ã–±—Ä–æ—Å–æ–≤ –¥–ª—è —Ñ–∞–π–ª–∞ {filename}: {e}\")\n",
    "                            continue\n",
    "                        \n",
    "                        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ (arcsinh)\n",
    "                        try:\n",
    "                            data_normalized = log_arcsinh_transform_data(data_no_outliers, \n",
    "                                                                           cofactor_mapping=None)\n",
    "                        except Exception as e:\n",
    "                            print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ñ–∞–π–ª–∞ {filename}: {e}\")\n",
    "                            continue\n",
    "                        \n",
    "                        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—É—Ç—å –∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞–º:\n",
    "                        # –ò–∑ base_dir (–Ω–∞–ø—Ä–∏–º–µ—Ä, ...\\Examples\\MM_subpopulations) –ø–æ–¥–Ω–∏–º–∞–µ–º—Å—è –Ω–∞ —É—Ä–æ–≤–µ–Ω—å –≤—ã—à–µ (...\\Examples)\n",
    "                        # –∏ –∑–∞—Ö–æ–¥–∏–º –≤ –ø–∞–ø–∫—É Saved_UMAP_n_csv\n",
    "                        examples_dir = os.path.dirname(base_dir)\n",
    "                        classifier_dir = os.path.join(examples_dir, \"Saved_UMAP_n_csv\")\n",
    "                        \n",
    "                        # –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ (.pkl), –∏–º—è –∫–æ—Ç–æ—Ä–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∏—Ç tube_prefix\n",
    "                        classifier_file = None\n",
    "                        if os.path.isdir(classifier_dir):\n",
    "                            for clf in os.listdir(classifier_dir):\n",
    "                                if clf.endswith(\".pkl\") and tube_prefix in clf:\n",
    "                                    classifier_file = os.path.join(classifier_dir, clf)\n",
    "                                    break\n",
    "                        else:\n",
    "                            print(f\"–ü–∞–ø–∫–∞ —Å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {classifier_dir}\")\n",
    "                            continue\n",
    "                        \n",
    "                        if classifier_file is None:\n",
    "                            print(f\"–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –¥–ª—è –ø—Ä–µ—Ñ–∏–∫—Å–∞ '{tube_prefix}' –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–ø—É—Å–∫ —Ñ–∞–π–ª–∞ {filename}.\")\n",
    "                            continue\n",
    "                        \n",
    "                        # –ó–∞–≥—Ä—É–∂–∞–µ–º UMAP-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä\n",
    "                        try:\n",
    "                            with open(classifier_file, \"rb\") as f:\n",
    "                                reducer = pickle.load(f)\n",
    "                        except Exception as e:\n",
    "                            print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ {classifier_file}: {e}\")\n",
    "                            continue\n",
    "                        \n",
    "                        # –ü—Ä–∏–º–µ–Ω—è–µ–º UMAP-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∫ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º –¥–∞–Ω–Ω—ã–º\n",
    "                        try:\n",
    "                            umap_result = reducer.transform(data_normalized)\n",
    "                        except Exception as e:\n",
    "                            print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ UMAP –∫ –¥–∞–Ω–Ω—ã–º —Ñ–∞–π–ª–∞ {filename}: {e}\")\n",
    "                            continue\n",
    "                        \n",
    "                        # –§–æ—Ä–º–∏—Ä—É–µ–º DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ UMAP\n",
    "                        umap_df = pd.DataFrame(umap_result, \n",
    "                                               columns=[f'UMAP{i+1}' for i in range(reducer.n_components)])\n",
    "                        \n",
    "                        # –°—Ç—Ä–æ–∏–º UMAP-—á–∞—Ä—Ç\n",
    "                        plt.figure(figsize=(8, 6))\n",
    "                        if reducer.n_components >= 2:\n",
    "                            plt.scatter(umap_df['UMAP1'], umap_df['UMAP2'], alpha=0.6, s=10)\n",
    "                            plt.xlabel('UMAP Component 1')\n",
    "                            plt.ylabel('UMAP Component 2')\n",
    "                        else:\n",
    "                            plt.scatter(range(len(umap_df)), umap_df['UMAP1'], alpha=0.6, s=10)\n",
    "                            plt.xlabel('Samples')\n",
    "                            plt.ylabel('UMAP Component 1')\n",
    "                        \n",
    "                        # –ü–æ–¥–ø–∏—Å—ã–≤–∞–µ–º –≥—Ä–∞—Ñ–∏–∫ –Ω–∞–∑–≤–∞–Ω–∏–µ–º —Ñ–∞–π–ª–∞\n",
    "                        plt.title(filename)\n",
    "                        plt.grid(True)\n",
    "                        plt.show()\n",
    "                        \n",
    "                        # –ï—Å–ª–∏ —Ñ–∞–π–ª —Å–æ–≤–ø–∞–ª —Å –æ–¥–Ω–∏–º –∏–∑ tube, —Ç–æ –Ω–µ –Ω—É–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä—è—Ç—å –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —ç–ª–µ–º–µ–Ω—Ç—ã —Å–ø–∏—Å–∫–∞\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaa668b-671c-4230-90f7-d697b1bfaa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "def process_test_data(dataframes, min_events=10000):\n",
    "    \"\"\"\n",
    "    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ:\n",
    "    1. –û–±—Ä–µ–∑–∞–µ—Ç –¥–æ min_events —Å—Ç—Ä–æ–∫ (–µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ).\n",
    "    2. –£–¥–∞–ª—è–µ—Ç –Ω–µ–Ω—É–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframes (pd.DataFrame or list of pd.DataFrame): –û–¥–∏–Ω –∏–ª–∏ —Å–ø–∏—Å–æ–∫ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–æ–≤.\n",
    "    - min_events (int): –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–±—ã—Ç–∏–π –¥–ª—è –æ–±—Ä–µ–∑–∫–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 100 000).\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame –∏–ª–∏ list –∏–∑ DataFrame (–µ—Å–ª–∏ –≤—Ö–æ–¥ –±—ã–ª —Å–ø–∏—Å–∫–æ–º).\n",
    "    \"\"\"\n",
    "    single_input = isinstance(dataframes, pd.DataFrame)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–µ—Ä–µ–¥–∞–Ω –ª–∏ –æ–¥–∏–Ω DataFrame\n",
    "    if single_input:\n",
    "        dataframes = [dataframes]  # –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º –≤ —Å–ø–∏—Å–æ–∫ –¥–ª—è –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
    "\n",
    "    print(f\"‚öôÔ∏è  –ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "\n",
    "    # –û–±—Ä–µ–∑–∞–µ–º –¥–æ –Ω—É–∂–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç—Ä–æ–∫ (–µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ)\n",
    "    processed_data = [\n",
    "        df.sample(n=min(min_events, len(df)), random_state=42).reset_index(drop=True)\n",
    "        for df in dataframes\n",
    "    ]\n",
    "    print(f\"‚úÖ –î–∞–Ω–Ω—ã–µ –æ–±—Ä–µ–∑–∞–Ω—ã (–∏–ª–∏ –æ—Å—Ç–∞–≤–ª–µ–Ω—ã –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π, –µ—Å–ª–∏ —Å—Ç—Ä–æ–∫ –º–µ–Ω—å—à–µ {min_events})\")\n",
    "\n",
    "    # –£–¥–∞–ª—è–µ–º —Å—Ç–æ–ª–±—Ü—ã, –æ–∫–∞–Ω—á–∏–≤–∞—é—â–∏–µ—Å—è –Ω–∞ '-A', 'Width', 'Time'\n",
    "    processed_data = [\n",
    "        df.drop(columns=[col for col in df.columns if col.endswith(('-A', 'Width', 'Time'))], errors=\"ignore\") \n",
    "        for df in processed_data\n",
    "    ]\n",
    "    print(f\"‚úÖ –£–¥–∞–ª–µ–Ω—ã —Å—Ç–æ–ª–±—Ü—ã: '-A', 'Width', 'Time' (–µ—Å–ª–∏ –±—ã–ª–∏)\")\n",
    "\n",
    "    return processed_data[0] if single_input else processed_data  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º DataFrame, –µ—Å–ª–∏ –±—ã–ª –æ–¥–∏–Ω –≤—Ö–æ–¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80979a0-32cc-47db-b605-0e021901a11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∏ –∫–æ–ª–æ—Ä–∏–∑—É–µ–º –º–æ–ª–µ–∫—É–ª—ã CD –∏ –ø—Ä–æ–≤–æ–¥–∏–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é\n",
    "def cd_color_gradients(data, cd='none', sample_type='', sample_name='', transparency=0.5, subsample=0.1):\n",
    "    \"\"\"\n",
    "    –°—Ç—Ä–æ–∏—Ç scatter plot UMAP1 vs UMAP2. \n",
    "    –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω cd, —Ç–æ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ —Ä–∞—Å–∫—Ä–∞—à–∏–≤–∞–µ—Ç —Ç–æ—á–∫–∏.\n",
    "    –ü–æ–∑–≤–æ–ª—è–µ—Ç —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ sample_type –∏ sample_name.\n",
    "\n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): –î–∞—Ç–∞—Ñ—Ä–µ–π–º —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ 'UMAP1' –∏ 'UMAP2'.\n",
    "    - cd (str): –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 'none' ‚Äî –±–µ–∑ –æ–∫—Ä–∞—à–∏–≤–∞–Ω–∏—è).\n",
    "    - sample_type (str): –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Ç–∏–ø—É –æ–±—Ä–∞–∑—Ü–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏).\n",
    "    - sample_name (str): –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∏–º–µ–Ω–∏ –æ–±—Ä–∞–∑—Ü–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏).\n",
    "    - transparency (float): –ü—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å —Ç–æ—á–µ–∫ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.5).\n",
    "    - subsample (float): –î–æ–ª—è —Ç–æ—á–µ–∫ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è (–æ—Ç 0 –¥–æ 1, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.1).\n",
    "\n",
    "    Returns:\n",
    "    - None (—Å—Ç—Ä–æ–∏—Ç –≥—Ä–∞—Ñ–∏–∫)\n",
    "    \"\"\"\n",
    "    if not (0 < subsample <= 1):\n",
    "        raise ValueError(\"subsample –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç 0 –¥–æ 1\")\n",
    "\n",
    "    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ sample_type, –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä\n",
    "    if sample_type and sample_type in data['sample_type'].unique():\n",
    "        data = data[data['sample_type'] == sample_type]\n",
    "\n",
    "    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ sample_name, –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä\n",
    "    if sample_name and sample_name in data['sample_name'].unique():\n",
    "        data = data[data['sample_name'] == sample_name]\n",
    "\n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ—Å—Ç–∞–ª–æ—Å—å –ª–∏ —á—Ç–æ-—Ç–æ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏\n",
    "    if data.empty:\n",
    "        print(\"‚ùå –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã sample_type –∏ sample_name.\")\n",
    "        return\n",
    "\n",
    "    # –í—ã–±–∏—Ä–∞–µ–º –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö\n",
    "    n_samples = max(int(len(data) * subsample), 1000)  # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –º–∏–Ω–∏–º—É–º 1000 —Ç–æ—á–µ–∫\n",
    "    sampled_data = data.sample(n=n_samples, random_state=42)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    if cd in data.columns:\n",
    "        # –°–æ–∑–¥–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫—É—é —Ü–≤–µ—Ç–æ–≤—É—é –∫–∞—Ä—Ç—É\n",
    "        colors = [(0, 'blue'), (0.5, 'yellow'), (1, 'red')]  # –°–∏–Ω–∏–π -> –ñ–µ–ª—Ç—ã–π -> –ö—Ä–∞—Å–Ω—ã–π\n",
    "        cmap = LinearSegmentedColormap.from_list('CustomMap', colors, N=256)\n",
    "\n",
    "        plt.scatter(sampled_data['UMAP1'], sampled_data['UMAP2'], \n",
    "                    c=sampled_data[cd], cmap=cmap, alpha=transparency)\n",
    "        plt.colorbar(label=cd)  # –î–æ–±–∞–≤–ª—è–µ–º —Ü–≤–µ—Ç–æ–≤—É—é —à–∫–∞–ª—É\n",
    "    else:\n",
    "        plt.scatter(sampled_data['UMAP1'], sampled_data['UMAP2'], \n",
    "                    color='gray', alpha=transparency)\n",
    "\n",
    "    plt.xlabel(\"UMAP1\")\n",
    "    plt.ylabel(\"UMAP2\")\n",
    "    title = f\"UMAP Projection {('with ' + cd) if cd in data.columns else ''}\"\n",
    "    if sample_type:\n",
    "        title += f\" | sample_type={sample_type}\"\n",
    "    if sample_name:\n",
    "        title += f\" | sample_name={sample_name}\"\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcd4046-ed13-4aa2-98b6-598b85f1eb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ .csv-—Ñ–∞–π–ª–∞ —Å —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ UMAP, –∏ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ–º, –∫–∞–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –≤–µ–ª–∏—á–∏–Ω—ã —Ñ–ª—É–æ—Ä–µ—Å—Ü–µ–Ω—Ü–∏–∏ –≤ UMAP-–∫–ª–∞—Å—Ç–µ—Ä–∞—Ö\n",
    "# –í–æ–∑–º–æ–∂–Ω–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è\n",
    "def process_umap_csv_and_plot(dirs, tube, sample_type=False, sample_name=False):\n",
    "    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ —Å–ø–∏—Å–∫—É tube\n",
    "    for sample_name_in_tube in tube:\n",
    "        # –°—Ç—Ä–æ–∏–º –ø—É—Ç—å –∫ .csv —Ñ–∞–π–ª—É –Ω–∞ –æ—Å–Ω–æ–≤–µ sample_name\n",
    "        # –ó–∞—Ö–æ–¥–∏–º –Ω–∞ –æ–¥–∏–Ω —É—Ä–æ–≤–µ–Ω—å –≤—ã—à–µ –ø–∞–ø–∫–∏ dirs[0] –∏ –≤ \\Saved_UMAP_n_csv\n",
    "        saved_umap_dir = os.path.join(os.path.dirname(dirs[0]), 'Saved_UMAP_n_csv')\n",
    "\n",
    "        # –ò—â–µ–º .csv —Ñ–∞–π–ª —Å –Ω—É–∂–Ω—ã–º –∏–º–µ–Ω–µ–º –∏ —Å–æ–¥–µ—Ä–∂–∞—â–∏–º —Å–ª–æ–≤–æ \"umap\" –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏\n",
    "        csv_file = None\n",
    "        for file in os.listdir(saved_umap_dir):\n",
    "            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –ø—Ä–µ—Ñ–∏–∫—Å–∞ –∏ \"umap\" –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞\n",
    "            if sample_name_in_tube.split('.')[0] in file and 'umap' in file.lower() and file.endswith('.csv'):\n",
    "                csv_file = os.path.join(saved_umap_dir, file)\n",
    "                break\n",
    "\n",
    "        if csv_file is None:\n",
    "            print(f\"–ù–µ –Ω–∞–π–¥–µ–Ω .csv —Ñ–∞–π–ª –¥–ª—è {sample_name_in_tube} –≤ –ø–∞–ø–∫–µ {saved_umap_dir}\")\n",
    "            continue\n",
    "\n",
    "        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞\n",
    "        data = pd.read_csv(csv_file)\n",
    "\n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Å—Ç–æ–ª–±—Ü–æ–≤, –∫—Ä–æ–º–µ —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è —Ç–∏–ø–∞ –æ–±—Ä–∞–∑—Ü–∞ –∏ 'UMAP1' –∏ 'UMAP2'\n",
    "        columns_to_plot = [col for col in data.columns if col not in ['sample_type', 'sample_name', 'UMAP1', 'UMAP2']]\n",
    "\n",
    "        # –ï—Å–ª–∏ sample_type=True, —Ç–æ –ø–µ—Ä–µ–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Å—Ç–æ–ª–±—Ü–µ sample_type\n",
    "        if sample_type:\n",
    "            unique_sample_types = data['sample_type'].unique()\n",
    "            for sample in unique_sample_types:\n",
    "                print(f\"–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –¥–ª—è sample_type: {sample}\")\n",
    "                # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ —Ç–µ–∫—É—â–µ–º—É –∑–Ω–∞—á–µ–Ω–∏—é sample_type\n",
    "                filtered_data = data[data['sample_type'] == sample]\n",
    "\n",
    "                # –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞ —Å—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫\n",
    "                for col in columns_to_plot:\n",
    "                    cd_color_gradients(filtered_data, cd=col, sample_type=sample, sample_name=sample_name_in_tube)\n",
    "        else:\n",
    "            # –ï—Å–ª–∏ sample_type=False, —Å—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫–∏ –¥–ª—è –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏\n",
    "            for col in columns_to_plot:\n",
    "                cd_color_gradients(data, cd=col, sample_type=sample_type, sample_name=sample_name_in_tube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380336de-29b0-4ece-ba61-f8f2904ce1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–ª–∏–≥–æ–Ω–æ–≤\n",
    "def umap_populations_plot(path, dirs, tube, polygons, subsample=0.1, sample_type=None, sample_name=None):\n",
    "    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç –∏–∑ tube –¥–æ –ø–µ—Ä–≤–æ–π —Ç–æ—á–∫–∏\n",
    "    tube_prefix = tube.split('.')[0]\n",
    "    \n",
    "    # 1. –°—Ç—Ä–æ–∏–º –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ Saved_UMAP_n_csv —á–µ—Ä–µ–∑ –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç –∏–∑ dirs\n",
    "    saved_path = os.path.join(os.path.dirname(dirs[0]), \"Saved_UMAP_n_csv\")\n",
    "    \n",
    "    # 2. –ò—â–µ–º –Ω—É–∂–Ω—ã–π CSV-—Ñ–∞–π–ª\n",
    "    matching_files = [f for f in os.listdir(saved_path) if tube_prefix in f and \"umap\" in f.lower() and f.endswith(\".csv\")]\n",
    "\n",
    "    if not matching_files:\n",
    "        raise FileNotFoundError(f\"–§–∞–π–ª —Å —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–º '{tube_prefix}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ {saved_path}\")\n",
    "    \n",
    "    csv_file = os.path.join(saved_path, matching_files[0])\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # 3. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö, –µ—Å–ª–∏ –∑–∞–¥–∞–Ω—ã sample_type –∏ sample_name\n",
    "    if sample_type is not None:\n",
    "        df = df[df[\"sample_type\"] == sample_type]\n",
    "    if sample_name is not None:\n",
    "        df = df[df[\"sample_name\"] == sample_name]\n",
    "\n",
    "    # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç, –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ\n",
    "    if df.empty:\n",
    "        print(f\"‚ö†Ô∏è –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö ({sample_type=}, {sample_name=}) –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å! –í–æ–∑–≤—Ä–∞—â–∞—é –ø—É—Å—Ç–æ–π DataFrame.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # 4. –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—É—é –ø–æ–¥–≤—ã–±–æ—Ä–∫—É\n",
    "    df_sampled = df.sample(frac=subsample, random_state=42) if subsample < 1.0 else df\n",
    "    \n",
    "    # 5. –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.scatter(df_sampled[\"UMAP1\"], df_sampled[\"UMAP2\"], s=5, alpha=0.5, label=\"Data\")\n",
    "    \n",
    "    # 6. –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª–∏–≥–æ–Ω—ã –∏ –º–µ—Ç–∫–∏\n",
    "    res = df.copy()\n",
    "    legend_entries = set()  # –•—Ä–∞–Ω–∏–º –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ (–∏–º—è, —Ü–≤–µ—Ç)\n",
    "\n",
    "    for poly in polygons:\n",
    "        name, color, *coords = poly\n",
    "        polygon = np.array(coords)\n",
    "        poly_patch = Polygon(polygon, edgecolor=color, facecolor=color, alpha=0.3)\n",
    "\n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –ª–µ–≥–µ–Ω–¥—É —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ç–∞–∫–æ–π (–∏–º—è, —Ü–≤–µ—Ç) –µ—â—ë –Ω–µ –±—ã–ª –¥–æ–±–∞–≤–ª–µ–Ω\n",
    "        if (name, color) not in legend_entries:\n",
    "            legend_entries.add((name, color))\n",
    "            poly_patch.set_label(name)  # –î–æ–±–∞–≤–ª—è–µ–º –∏–º—è —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑\n",
    "\n",
    "        ax.add_patch(poly_patch)\n",
    "\n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–∏–µ —Ç–æ—á–∫–∏ –ø–æ–ø–∞–¥–∞—é—Ç –≤–Ω—É—Ç—Ä—å –ø–æ–ª–∏–≥–æ–Ω–∞\n",
    "        path = Path(polygon)\n",
    "        inside = path.contains_points(df[[\"UMAP1\", \"UMAP2\"]].values)\n",
    "        if name in res:\n",
    "            res[name] |= inside.astype(np.int8)  # –õ–æ–≥–∏—á–µ—Å–∫–æ–µ –ò–õ–ò\n",
    "        else:\n",
    "            res[name] = inside.astype(np.int8)  # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–∫ int8\n",
    "\n",
    "    ax.legend()\n",
    "    plt.xlabel(\"UMAP1\")\n",
    "    plt.ylabel(\"UMAP2\")\n",
    "    plt.title(f\"UMAP Populations: {tube}\")\n",
    "    plt.show()\n",
    "\n",
    "    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –ø–æ–ª–∏–≥–æ–Ω–æ–≤ —Å –∏–Ω–¥–µ–∫—Å–æ–º n\n",
    "    polygon_data = []\n",
    "    polygon_counts = {}  # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π\n",
    "    \n",
    "    for i, poly in enumerate(polygons):\n",
    "        name, color, *coords = poly\n",
    "        if name not in polygon_counts:\n",
    "            polygon_counts[name] = 1\n",
    "        else:\n",
    "            polygon_counts[name] += 1\n",
    "    \n",
    "        poly_index = polygon_counts[name]  # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –Ω–∞–∑–≤–∞–Ω–∏—è\n",
    "    \n",
    "        for x, y in coords:\n",
    "            polygon_data.append([name, color, x, y, poly_index])\n",
    "    \n",
    "    polygon_df = pd.DataFrame(polygon_data, columns=[\"name\", \"color\", \"x\", \"y\", \"n\"])\n",
    "    polygon_df.to_csv(os.path.join(saved_path, f\"polygons_{tube_prefix}.csv\"), index=False)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa48756-66d6-4b6b-8bdc-d0ec82372bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_data(path, tube, pdf=False, fcs_del=True):\n",
    "    reports_dir = os.path.join(path, \"Reports\")\n",
    "    os.makedirs(reports_dir, exist_ok=True)  # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É Reports –≤ path\n",
    "\n",
    "    saved_path = os.path.join(path, \"Examples\", \"Saved_UMAP_n_csv\")  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –ø—É—Ç—å –∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä—É\n",
    "\n",
    "    # –û–±—Ö–æ–¥–∏–º –≤—Å–µ –ø–∞–ø–∫–∏ –≤ –∫–æ—Ä–Ω–µ–≤–æ–º –∫–∞—Ç–∞–ª–æ–≥–µ, –∏—Å–∫–ª—é—á–∞—è —Å–ª—É–∂–µ–±–Ω—ã–µ –ø–∞–ø–∫–∏\n",
    "    for folder_name in sorted(os.listdir(path)):\n",
    "        if folder_name in [\"Reports\", \"Examples\"]:\n",
    "            continue\n",
    "\n",
    "        folder_path = os.path.join(path, folder_name)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        # –°–æ–±–∏—Ä–∞–µ–º —Ñ–∞–π–ª—ã –ø–æ –ø–æ—Ä—è–¥–∫—É tube\n",
    "        ordered_files = []\n",
    "        for tube_item in tube:\n",
    "            tube_prefix = tube_item.split('.')[0]\n",
    "            files_for_prefix = [f for f in os.listdir(folder_path) if tube_prefix in f and f.endswith(\".fcs\")]\n",
    "            ordered_files.extend(files_for_prefix)\n",
    "\n",
    "        if not ordered_files:\n",
    "            continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–∞–ø–∫—É, –µ—Å–ª–∏ –Ω–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö .fcs —Ñ–∞–π–ª–æ–≤\n",
    "\n",
    "        pdf_pages = None\n",
    "        if pdf:\n",
    "            pdf_path = os.path.join(reports_dir, f\"Report of {folder_name}.pdf\")\n",
    "            pdf_pages = PdfPages(pdf_path)\n",
    "            csv_path = os.path.join(reports_dir, f\"Report_of_{folder_name}.csv\")\n",
    "\n",
    "        print(f\"\\n–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –ø–∞–ø–∫—É: {folder_name}\")\n",
    "        for filename in ordered_files:\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º tube_prefix\n",
    "            tube_prefix = None\n",
    "            for tube_item in tube:\n",
    "                prefix = tube_item.split('.')[0]\n",
    "                if prefix in filename:\n",
    "                    tube_prefix = prefix\n",
    "                    break\n",
    "            if tube_prefix is None:\n",
    "                print(f\"–ü—Ä–µ—Ñ–∏–∫—Å –¥–ª—è —Ñ–∞–π–ª–∞ {filename} –Ω–µ –Ω–∞–π–¥–µ–Ω.\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                meta, data = parse(file_path)\n",
    "                del meta\n",
    "                data_no_outliers = remove_outliers_percentile(data)\n",
    "                data_normalized = log_arcsinh_transform_data(data_no_outliers)\n",
    "            except Exception as e:\n",
    "                print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {filename}: {e}\")\n",
    "                continue\n",
    "\n",
    "            classifier_file = None\n",
    "            if os.path.isdir(saved_path):\n",
    "                for clf in os.listdir(saved_path):\n",
    "                    if clf.endswith(\".pkl\") and tube_prefix in clf:\n",
    "                        classifier_file = os.path.join(saved_path, clf)\n",
    "                        break\n",
    "            if classifier_file is None:\n",
    "                print(f\"–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –¥–ª—è {tube_prefix} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ {saved_path}.\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                with open(classifier_file, \"rb\") as f:\n",
    "                    reducer = pickle.load(f)\n",
    "                umap_result = reducer.transform(data_normalized)\n",
    "            except Exception as e:\n",
    "                print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ UMAP {filename}: {e}\")\n",
    "                continue\n",
    "\n",
    "            umap_df = pd.DataFrame(umap_result, columns=[f'UMAP{i+1}' for i in range(reducer.n_components)])\n",
    "\n",
    "            polygon_file = os.path.join(saved_path, f\"polygons_{tube_prefix}.csv\")\n",
    "            if not os.path.exists(polygon_file):\n",
    "                print(f\"–§–∞–π–ª —Å –ø–æ–ª–∏–≥–æ–Ω–∞–º–∏ {polygon_file} –Ω–µ –Ω–∞–π–¥–µ–Ω.\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                polygons_df = pd.read_csv(polygon_file)\n",
    "            except Exception as e:\n",
    "                print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø–æ–ª–∏–≥–æ–Ω–æ–≤ {polygon_file}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # ---- –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è UMAP ----\n",
    "            fig, ax = plt.subplots(figsize=(10, 8))\n",
    "            ax.scatter(umap_df[\"UMAP1\"], umap_df[\"UMAP2\"], s=5, alpha=0.5, label=\"Data\")\n",
    "\n",
    "            umap_df_result = umap_df.copy()\n",
    "            polygon_groups = {}\n",
    "            added_legend_items = set()\n",
    "\n",
    "            for (name, n) in polygons_df[[\"name\", \"n\"]].drop_duplicates().itertuples(index=False):\n",
    "                poly_data = polygons_df[(polygons_df[\"name\"] == name) & (polygons_df[\"n\"] == n)]\n",
    "                polygon = np.array(list(zip(poly_data[\"x\"], poly_data[\"y\"])))\n",
    "                poly_color = poly_data[\"color\"].iloc[0]\n",
    "                legend_key = (name, poly_color)\n",
    "                poly_patch = Polygon(polygon, edgecolor=poly_color, facecolor=\"none\", lw=2)\n",
    "                ax.add_patch(poly_patch)\n",
    "                if legend_key not in added_legend_items:\n",
    "                    ax.plot([], [], color=poly_color, label=name)\n",
    "                    added_legend_items.add(legend_key)\n",
    "                path_obj = Path(polygon)\n",
    "                inside = path_obj.contains_points(umap_df[[\"UMAP1\", \"UMAP2\"]].values).astype(np.int32)\n",
    "                if name in polygon_groups:\n",
    "                    polygon_groups[name] |= inside\n",
    "                else:\n",
    "                    polygon_groups[name] = inside\n",
    "\n",
    "            for name, inside_mask in polygon_groups.items():\n",
    "                umap_df_result[name] = inside_mask\n",
    "\n",
    "            ax.legend()\n",
    "            plt.xlabel(\"UMAP1\")\n",
    "            plt.ylabel(\"UMAP2\")\n",
    "            plt.title(f\"–¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ: {filename}\")\n",
    "\n",
    "            # ---- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ ----\n",
    "            stats = umap_df_result.describe().T.iloc[2:, :2]\n",
    "            if \"Trash\" in umap_df_result.columns:\n",
    "                total_cells = len(umap_df_result)\n",
    "                trash_count = (umap_df_result[\"Trash\"] == 1).sum()\n",
    "                granulocytes_count = (umap_df_result[\"Granulocytes\"] == 1).sum() if \"Granulocytes\" in umap_df_result.columns else 0\n",
    "                mononuclears = total_cells - trash_count - granulocytes_count\n",
    "                stats.loc[\"Mononuclears\", [\"count\", \"mean\"]] = [mononuclears, mononuclears / total_cells * 100]\n",
    "                if \"Granulocytes\" in umap_df_result.columns:\n",
    "                    stats.loc[\"Granulocytes\", [\"count\", \"mean\"]] = [granulocytes_count, granulocytes_count / (total_cells - trash_count) * 100]\n",
    "                for pop in polygon_groups.keys():\n",
    "                    if pop in umap_df_result.columns and pop not in [\"Trash\", \"Granulocytes\"]:\n",
    "                        count = umap_df_result[pop].sum()\n",
    "                        stats.loc[pop, [\"count\", \"mean\"]] = [count, count / mononuclears * 100]\n",
    "\n",
    "            stats.columns = ['–ê–±—Å. –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ', '–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ, %']\n",
    "            stats['–ê–±—Å. –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ'] = stats['–ê–±—Å. –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ'].astype(np.int32)\n",
    "            stats['–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ, %'] = stats['–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ, %'].astype(np.float32).round(4)\n",
    "            stats = stats.drop(\"Trash\", errors=\"ignore\")\n",
    "\n",
    "            print(f\"\\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è –ø—Ä–æ–±–∏—Ä–∫–∏ {filename} (–ø–∞—Ü–∏–µ–Ω—Ç: {folder_name}):\")\n",
    "            plt.show()\n",
    "            display(stats)\n",
    "            plt.close(fig)\n",
    "\n",
    "            if pdf and pdf_pages:\n",
    "                pdf_pages.savefig(fig)\n",
    "                plt.close(fig)\n",
    "                fig_table, ax_table = plt.subplots(figsize=(8, 4))\n",
    "                ax_table.axis('tight')\n",
    "                ax_table.axis('off')\n",
    "                table_data = stats.reset_index().values.tolist()\n",
    "                table_data.insert(0, [\"–ì—Ä—É–ø–ø–∞\", \"–ê–±—Å. –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ\", \"–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ, %\"])\n",
    "                ax_table.table(cellText=table_data, loc=\"center\", cellLoc=\"center\")\n",
    "                plt.title(f\"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è –æ–±—Ä–∞–∑—Ü–∞ {folder_name}.\")\n",
    "                pdf_pages.savefig(fig_table)\n",
    "                plt.close(fig_table)\n",
    "            if pdf:\n",
    "                stats.to_csv(csv_path, mode='a', header=not os.path.exists(csv_path))\n",
    "                print(f\"–û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {csv_path}\")\n",
    "\n",
    "        if pdf and pdf_pages:\n",
    "            pdf_pages.close()\n",
    "            print(f\"–û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {pdf_path}\")\n",
    "\n",
    "        if fcs_del:\n",
    "            shutil.rmtree(folder_path)\n",
    "            print(f\"–£–¥–∞–ª–µ–Ω–∞ –ø–∞–ø–∫–∞: {folder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f6cac4-ff5c-4e9e-9057-bee81a8b3664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç—á—ë—Ç–æ–≤\n",
    "def make_report(path, blanks, coordinates, clean=True):\n",
    "    reports_folder = os.path.join(path, \"Reports\")\n",
    "    \n",
    "    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ CSV-—Ñ–∞–π–ª–æ–≤, —É–±–∏—Ä–∞—è \"Report_of_\" –∏–∑ –Ω–∞—á–∞–ª–∞\n",
    "    report_files = [f for f in os.listdir(reports_folder) if f.endswith(\".csv\")]\n",
    "    report_names = [f.replace(\"Report_of_\", \"\").replace(\".csv\", \"\") for f in report_files]\n",
    "\n",
    "    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç, –Ω–µ –ø—Ä–µ–≤—Ä–∞—â–∞—è –ø–µ—Ä–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü –≤ –∏–Ω–¥–µ–∫—Å\n",
    "    coordinates_file = os.path.join(coordinates, \"Coordinates.xlsx\")\n",
    "    df_coords = pd.read_excel(coordinates_file, index_col=None)\n",
    "\n",
    "    for report_name in report_names:\n",
    "        csv_path = os.path.join(reports_folder, f\"Report_of_{report_name}.csv\")\n",
    "\n",
    "        # –ò—â–µ–º –ø–æ–¥—Ö–æ–¥—è—â–∏–π XLSX-—Ñ–∞–π–ª –≤ –ø–∞–ø–∫–µ blanks (–Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å report_name, –∑–∞—Ç–µ–º –ª—é–±—ã–µ —Å–∏–º–≤–æ–ª—ã)\n",
    "        matching_files = [f for f in os.listdir(blanks) if re.match(fr\"^{re.escape(report_name)}.*\\.xlsx$\", f)]\n",
    "        if not matching_files:\n",
    "            continue\n",
    "\n",
    "        # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª (–µ—Å–ª–∏ –∏—Ö –Ω–µ—Å–∫–æ–ª—å–∫–æ)\n",
    "        xlsx_path = os.path.join(blanks, matching_files[0])\n",
    "        if not os.path.exists(csv_path):\n",
    "            continue\n",
    "\n",
    "        # –ó–∞–≥—Ä—É–∂–∞–µ–º CSV-—Ñ–∞–π–ª —Å —É—á–µ—Ç–æ–º —Ö–µ–¥–µ—Ä–∞\n",
    "        df_report = pd.read_csv(csv_path, header=0)\n",
    "        \n",
    "        # –ü–æ–ª—É—á–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞ CSV\n",
    "        filter_value = df_report.iloc[0, 0]\n",
    "        \n",
    "        # –§–∏–ª—å—Ç—Ä—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –ø–æ —Å—Ç–æ–ª–±—Ü—É \"Col0str1_in_report\"\n",
    "        df_filtered = df_coords[df_coords[\"Col0str1_in_report\"] == filter_value]\n",
    "        if df_filtered.empty:\n",
    "            continue\n",
    "\n",
    "        # –û—Ç–∫—Ä—ã–≤–∞–µ–º XLSX –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä—ã —è—á–µ–µ–∫\n",
    "        wb = load_workbook(xlsx_path)\n",
    "        ws = wb.active\n",
    "        column_widths = {col: ws.column_dimensions[col].width for col in ws.column_dimensions}\n",
    "        row_heights = {row: ws.row_dimensions[row].height for row in ws.row_dimensions}\n",
    "\n",
    "        # –ü–µ—Ä–µ–Ω–æ—Å –¥–∞–Ω–Ω—ã—Ö —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ Data_in_report_position\n",
    "        for _, row in df_filtered.iterrows():\n",
    "            blank_cell = str(row[\"Data_in_blank_position\"]).strip()\n",
    "            if pd.isna(row[\"Data_in_report_position\"]):\n",
    "                ws[blank_cell] = 0\n",
    "                ws[blank_cell].number_format = '0.00'\n",
    "            else:\n",
    "                report_index = int(row[\"Data_in_report_position\"])\n",
    "                if report_index < len(df_report):\n",
    "                    # –ë–µ—Ä–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å—Ç–æ–ª–±—Ü–∞ \"Mean, %\" (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ —ç—Ç–æ —Ç—Ä–µ—Ç–∏–π —Å—Ç–æ–ª–±–µ—Ü)\n",
    "                    value_to_copy = df_report.iloc[report_index, 2]\n",
    "                    ws[blank_cell] = value_to_copy\n",
    "                    ws[blank_cell].number_format = '0.00'\n",
    "                    \n",
    "        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã —è—á–µ–µ–∫\n",
    "        for col, width in column_widths.items():\n",
    "            ws.column_dimensions[col].width = width\n",
    "        for row, height in row_heights.items():\n",
    "            ws.row_dimensions[row].height = height\n",
    "\n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º XLSX\n",
    "        wb.save(xlsx_path)\n",
    "        wb.close()\n",
    "\n",
    "        # –£–¥–∞–ª—è–µ–º CSV, –µ—Å–ª–∏ clean=True\n",
    "        if clean:\n",
    "            os.remove(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6771ca81-441c-402a-bddb-9555b96b9573",
   "metadata": {},
   "source": [
    "# –ü—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö, –æ–±—É—á–µ–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ UMAP-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fde981a-5a5a-44b8-a8e0-0f2594e7d110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –£–∫–∞–∂–µ–º –∞–¥—Ä–µ—Å–∞ –ø–∞–ø–æ–∫ —Å —Å—ã—Ä—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏, –ø—Ä–æ–±–∏—Ä–∫—É –∏ –≤—ã–∑–æ–≤–µ–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º UMAP\n",
    "dirs = [path + r\"\\Examples\\Normal_MM\", \n",
    "        path + r\"\\Examples\\MM\"]\n",
    "tube = [r\"10_56_45_19_138_38.fcs\", r\"Œª_Œ∫_45_117_138_38.fcs\", r\"xx_79a_45_Ki67_3_xx.fcs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8634ec29-d4e8-4667-8709-76484ed10bf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è UMAP\n",
    "train_umap_data_organiser(dirs, tube, size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a6fdfe-2514-404b-89e5-598dde8af453",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±—É—á–∞–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã UMAP –ø–æ –ø–æ–ª—É—á–µ–Ω–Ω—ã–º –¥–∞–Ω–Ω—ã–º, –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º\n",
    "process_and_save_umap(dirs, \n",
    "                      tube, \n",
    "                      n_neighbors=25, \n",
    "                      min_dist=0.001, \n",
    "                      metric=\"manhattan\", \n",
    "                      n_epochs=None,            # n_epochs=None –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é. –î–ª—è –±–æ–ª–µ–µ 10–∫ —Ç–æ—á–µ–∫ —ç—Ç–æ 200\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fd1ffe-d507-481f-a1c8-5c18bac3a95c",
   "metadata": {},
   "source": [
    "# –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–∞–±–æ—Ç—ã UMAP-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7a8cb9-6dcb-4992-bcb6-8b7e4a4f0b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f97b9d-710d-43c9-a069-f997a1cbdd4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# –í—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏ —Å –ø–µ—Ä–µ–¥–∞—á–µ–π –Ω—É–∂–Ω—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –∏ —Å–ø–∏—Å–∫–∞ tube\n",
    "process_umap_csv_and_plot(dirs, tube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccea1ff-4a99-4985-92d4-432a3d7f12df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# –í—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏ —Å –ø–µ—Ä–µ–¥–∞—á–µ–π –Ω—É–∂–Ω—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –∏ —Å–ø–∏—Å–∫–∞ tube, –∏ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ —Ç–∏–ø—É –æ–±—Ä–∞–∑—Ü–∞\n",
    "process_umap_csv_and_plot(dirs, tube, sample_type=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b15ffc-2ddf-4459-aae3-1ae064cf8a31",
   "metadata": {},
   "source": [
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –ø–æ–ø—É–ª—è—Ü–∏–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3f9e90-664c-4d8c-b455-15f4eaa3ea90",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [path + r\"\\Examples\\MM_subpopulations\"]  # –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π –ø–∞–ø–∫–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecccbf17-9e55-4877-855d-d55cc9f3b849",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "process_validation_data(dirs, tube=[r\"10_56_45_19_138_38.fcs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88971231-24c7-4c32-909e-0f81b44f9769",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "process_validation_data(dirs, tube=[r\"Œª_Œ∫_45_117_138_38.fcs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d032755-2389-4443-ac6e-b62532eac007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "process_validation_data(dirs, tube=[r\"xx_79a_45_Ki67_3.fcs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974c918e-9c6b-461c-a1d9-3ce80dd54dc1",
   "metadata": {},
   "source": [
    "# –ê–Ω–∞–ª–∏–∑ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Å–ª—É—á–∞—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9ba7dc-edb0-4e33-aa95-c2f4d22d382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [path + r\"\\Examples\\Test_MM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42adebd0-abba-4f92-b92f-301b07faf75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "process_validation_data(dirs, tube=[r\"10_56_45_19_138_38.fcs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31285763-e843-4ae8-b9ea-aebe8a5f7cc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "process_validation_data(dirs, tube=[r\"Œª_Œ∫_45_117_138_38.fcs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169db836-86ce-4254-ad47-d8cd3ec22710",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "process_validation_data(dirs, tube=[r\"xx_79a_45_Ki67_3.fcs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93b75dd-c197-4ad9-8552-78209bb449ee",
   "metadata": {},
   "source": [
    "# –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ —Ä–∞–∑–º–µ—Ç–∫–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095c2f44-3120-4f0a-92a6-a8feffeb60ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [path + r\"\\Examples\\Normal_MM\", \n",
    "        path + r\"\\Examples\\MM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b087a2af-4bbb-437b-97c9-62e7b5a669fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–æ–ª–∏–≥–æ–Ω—ã\n",
    "res = umap_populations_plot(\n",
    "    path=path, dirs=dirs,\n",
    "    tube=\"10_56_45_19_138_38.fcs\",\n",
    "    polygons=[\n",
    "        [\"CD138+CD56+CD38+\", \"gray\", (2, 15), (4, 15), (5, 13), (6.5, 11), (5.5, 9.3), (4, 9)],\n",
    "        [\"CD138+CD38+\", \"red\", (2, 15), (4, 15), (5, 13), (6.5, 11), (5.5, 9.3), (4, 9)],\n",
    "        [\"Plasma cells\", \"orange\", (7.5, 8), (8.5, 9), (9, 8.6), (9.5, 8), (10, 6), (8.5, 6)],\n",
    "        [\"Plasma cells\", \"orange\", (4, 9), (6.8, 9.5), (5, 6)],\n",
    "        [\"CD138+\", \"red\", (2, 15), (4, 15), (5, 13), (6.5, 11), (5.5, 9.3), (4, 9)],\n",
    "        [\"CD138+\", \"red\", (7.5, 8), (8.5, 9), (9, 8.6), (9.5, 8), (10, 6), (8.5, 6)],\n",
    "        [\"CD38+\", \"brown\", (7.5, 8), (8.5, 9), (9, 8.6), (9.5, 8), (10, 6), (8.5, 6)],\n",
    "        [\"CD138+CD38+\", \"red\", (7.5, 8), (8.5, 9), (9, 8.6), (9.5, 8), (10, 6), (8.5, 6)],\n",
    "        [\"CD38+\", \"brown\", (2, 15), (4, 15), (5, 13), (6.5, 11), (5.5, 9.3), (4, 9)],\n",
    "        [\"CD10+\", \"green\", (6.5, 11.5), (7.5, 13), (8, 12), (7.5, 11)],\n",
    "        [\"CD56+\", \"yellow\", (2, 15), (4, 15), (5, 13), (6.5, 11), (5.5, 9.3), (4, 9)],\n",
    "        [\"Lymphocytes\", \"teal\", (5, -2), (9, 0), (12, -5)],\n",
    "        [\"CD56+\", \"yellow\", (6, -2), (8.5,-1), (9, -4)],\n",
    "        [\"CD19+\", \"blue\", (8.5, -1), (9, -0.5), (9.5, -1.5), (8.65, -1.75)],\n",
    "        [\"CD19+\", \"blue\", (4, 9), (6.8, 9.5), (5, 6)],\n",
    "        [\"CD38+\", \"brown\", (7, -2.3), (7, -1.3), (8.5, -1.3), (8.5, -2.3)],\n",
    "        [\"Monocytes\", \"blue\", (10, 5), (10.5, 7.5), (11, 7.5), (11, 5), (11.5, 4), (11, 3), (10.2, 4.2)],\n",
    "        [\"Granulocytes\", \"orange\", (12, 9), (18, 9), (18, 1.5), (16.5, 1.5), (15.5, 5), (13, 7.3), (11.5, 8)],\n",
    "        [\"Granulocytes\", \"yellow\", (11.5, 8), (13, 7.3), (15.5, 5), (16.5, 1.5), (12.5, 2), (11.5, 4), (11, 5)],\n",
    "        [\"Trash\", \"black\", (-7, 15), (0, 15), (3, 7), (5, 6), (7, 10), (8, 12), (9, 16), \n",
    "        (12.5, 16), (10, 12.5), (8, 10), (7.5, 8), (8, 7), (9.7, 3), (5, -2), (5, -8), (-7, -7)]\n",
    "    ],\n",
    "    subsample=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab3d0bd-57f4-4128-9cf7-3450eb63278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c55dc19-09ce-4a4d-ba27-b2b053e0165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res['Trash'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005b4f8e-5dde-4311-9ace-205cbd22074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37712bb-2098-4549-9b45-a19f986e96d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "types = res.sample_type.unique().tolist()\n",
    "samples = res.sample_name.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be965723-7218-4a79-b54f-e5ff9fd826a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in types:\n",
    "    for j in samples:\n",
    "        res = umap_populations_plot(\n",
    "            path=path, dirs=dirs,\n",
    "            tube=\"10_56_45_19_138_38.fcs\",\n",
    "            sample_type=i,\n",
    "            sample_name=j,\n",
    "            polygons=[\n",
    "                [\"CD138+CD56+CD38+\", \"gray\", (2, 15), (4, 15), (5, 13), (6.5, 11), (5.5, 9.3), (4, 9)],\n",
    "                [\"CD138+CD38+\", \"red\", (2, 15), (4, 15), (5, 13), (6.5, 11), (5.5, 9.3), (4, 9)],\n",
    "                [\"Plasma cells\", \"orange\", (7.5, 8), (8.5, 9), (9, 8.6), (9.5, 8), (9.7, 7), (10, 6), (8.5, 6)],\n",
    "                [\"Plasma cells\", \"orange\", (4, 9), (6.8, 9.5), (5, 6)],\n",
    "                [\"CD138+\", \"red\", (2, 15), (4, 15), (5, 13), (6.5, 11), (5.5, 9.3), (4, 9)],\n",
    "                [\"CD138+\", \"red\", (7.5, 8), (8.5, 9), (9, 8.6), (9.5, 8), (10, 6), (8.5, 6)],\n",
    "                [\"CD38+\", \"brown\", (7.5, 8), (8.5, 9), (9, 8.6), (9.5, 8), (10, 6), (8.5, 6)],\n",
    "                [\"CD138+CD38+\", \"red\", (7.5, 8), (8.5, 9), (9, 8.6), (9.5, 8), (10, 6), (8.5, 6)],\n",
    "                [\"CD38+\", \"brown\", (2, 15), (4, 15), (5, 13), (6.5, 11), (5.5, 9.3), (4, 9)],\n",
    "                [\"CD10+\", \"green\", (6.5, 11.5), (7.5, 13), (8, 12), (7.5, 11)],\n",
    "                [\"CD56+\", \"yellow\", (2, 15), (4, 15), (5, 13), (6.5, 11), (5.5, 9.3), (4, 9)],\n",
    "                [\"Lymphocytes\", \"teal\", (5, -2), (9, 0), (12, -5)],\n",
    "                [\"CD56+\", \"yellow\", (6, -2), (8.5,-1), (9, -4)],\n",
    "                [\"CD19+\", \"blue\", (8.5, -1), (9, -0.5), (9.5, -1.5), (8.65, -1.75)],\n",
    "                [\"CD19+\", \"blue\", (4, 9), (6.8, 9.5), (5, 6)],\n",
    "                [\"CD38+\", \"brown\", (7, -2.3), (7, -1.3), (8.5, -1.3), (8.5, -2.3)],\n",
    "                [\"Monocytes\", \"blue\", (10, 5), (10.5, 7.5), (11, 7.5), (11, 5), (11.5, 4), (11, 3), (10.2, 4.2)],\n",
    "                [\"Granulocytes\", \"orange\", (12, 9), (18, 9), (18, 1.5), (16.5, 1.5), (15.5, 5), (13, 7.3), (11.5, 8)],\n",
    "                [\"Granulocytes\", \"yellow\", (11.5, 8), (13, 7.3), (15.5, 5), (16.5, 1.5), (12.5, 2), (11.5, 4), (11, 5)],\n",
    "                [\"Trash\", \"black\", (-7, 15), (0, 15), (3, 7), (5, 6), (7, 10), (8, 12), (9, 16), \n",
    "                (12.5, 16), (10, 12.5), (8, 10), (7.5, 8), (8, 7), (9.7, 3), (5, -2), (5, -8), (-7, -7)]\n",
    "            ],\n",
    "            subsample=1\n",
    "        )\n",
    "\n",
    "        print(i)\n",
    "        print(j)\n",
    "        if res is not None and not res.empty:\n",
    "            print(res.describe().T.tail(9).iloc[:, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9192a0-ecbc-44e4-afa7-5f1bd8976933",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–æ–ª–∏–≥–æ–Ω—ã\n",
    "res = umap_populations_plot(\n",
    "    path=path, dirs=dirs,\n",
    "    tube=\"Œª_Œ∫_45_117_138_38.fcs\",\n",
    "    polygons=[\n",
    "        [\"CD138+CD38+\", \"gray\", (5, 12), (7, 10), (6.8, 8.3), (6, 7.7), (7.3, 5), (7.5, 4.5), (2, 7)],\n",
    "        [\"CD117+\", \"violet\", (7.3, 10.9), (8.8, 9.6), (8.8, 7.5), (7, 10),\n",
    "        (6.8, 8.3), (6, 7.7), (5.8, 9), (6, 9.8), (7, 10)],\n",
    "        [\"kappa+\", \"pink\", (5, 12), (6, 10), (6, 9), (6, 7.8), (5, 8.25), (4, 10)],\n",
    "        [\"lambda+\", \"green\", (4, 10.2), (5, 8.25), (6, 7.8), (7.5, 4.5), (2, 7)],\n",
    "        [\"Plasma cells\", \"orange\", (5, 12), (7, 10), (6.8, 8.3), (6, 7.7), (7.5, 4.5), (2, 7)],\n",
    "        [\"Lymphocytes\", \"teal\", (11, -2), (16, -1), (10, -8)],\n",
    "        [\"Monocytes\", \"blue\", (6.8, 8.3), (8, 8), (9, 7), (9.3, 5), (7.8, 6), (7, 6.7), (6.3, 6.7), (6, 7.7)],\n",
    "        [\"Granulocytes\", \"orange\", (10, 10), (13.5, 12.5), (18, 8), (18, 1.5), (15.5, 3.5), (12.5, 2.5), (10, 6)],\n",
    "        [\"Trash\", \"black\", (7.5, 4.8), (8, 5.3), (9, 5), (9, -10), (-5, -10), (-5, 15), (6, 15),\n",
    "        (7.5, 12), (7, 10), (5, 12), (2, 7), (5, 2.5)]\n",
    "    ],\n",
    "    subsample=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e06694f-5206-47c0-aa80-b5b086ed9d46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in types:\n",
    "    for j in samples:\n",
    "        res = umap_populations_plot(\n",
    "            path=path, dirs=dirs,\n",
    "            tube=\"Œª_Œ∫_45_117_138_38.fcs\",\n",
    "            sample_type=i,\n",
    "            sample_name=j,\n",
    "            polygons=[\n",
    "                [\"CD138+CD38+\", \"gray\", (5, 12), (7, 10), (6.8, 8.3), (6, 7.7), (7.3, 5), (7.5, 4.5), (2, 7)],\n",
    "                [\"CD117+\", \"violet\", (7.3, 10.9), (8.8, 9.6), (8.8, 7.5), (7, 10),\n",
    "                (6.8, 8.3), (6, 7.7), (5.8, 9), (6, 9.8), (7, 10)],\n",
    "                [\"kappa+\", \"pink\", (5, 12), (6, 10), (6, 9), (6, 7.8), (5, 8.25), (4, 10)],\n",
    "                [\"lambda+\", \"green\", (4, 10.2), (5, 8.25), (6, 7.8), (7.5, 4.5), (2, 7)],\n",
    "                [\"Plasma cells\", \"orange\", (5, 12), (7, 10), (6.8, 8.3), (6, 7.7), (7.5, 4.5), (2, 7)],\n",
    "                [\"Lymphocytes\", \"teal\", (11, -2), (16, -1), (10, -8)],\n",
    "                [\"Monocytes\", \"blue\", (6.8, 8.3), (8, 8), (9, 7), (9.3, 5), (7.8, 6), (7, 6.7), (6.3, 6.7), (6, 7.7)],\n",
    "                [\"Granulocytes\", \"orange\", (10, 10), (13.5, 12.5), (18, 8), (18, 1.5), (15.5, 3.5), (12.5, 2.5), (10, 6)],\n",
    "                [\"Trash\", \"black\", (7.5, 4.8), (8, 5.3), (9, 5), (9, -10), (-5, -10), (-5, 15), (6, 15),\n",
    "                (7.5, 12), (7, 10), (5, 12), (2, 7), (5, 2.5)]\n",
    "            ],\n",
    "            subsample=1\n",
    "        )\n",
    "\n",
    "        print(i)\n",
    "        print(j)\n",
    "        if res is not None and not res.empty:\n",
    "            print(res.describe().T.tail(9).iloc[:, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29989501-0e94-4b77-ab4a-b3856829210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–æ–ª–∏–≥–æ–Ω—ã\n",
    "res = umap_populations_plot(\n",
    "    path=path, dirs=dirs,\n",
    "    tube=\"xx_79a_45_Ki67_3_xx.fcs\",\n",
    "    polygons=[\n",
    "        [\"Plasma cells\", \"orange\", (11, 7.5), (12, 10), (14, 7.5), (13, 5), (11, 2.6), (10, 6), (10, 7)],\n",
    "        [\"Lymphocytes\", \"teal\", (7, 4), (10, 4), (10, 1), (7.5, -1.5), (7, -1.5)],\n",
    "        [\"Lymphocytes\", \"teal\", (9.5, 6), (10, 6), (10, 5), (9, 4.5)],\n",
    "        [\"CD79a+\", \"yellow\", (9.5, 6), (10, 6), (10, 5), (9, 4.5)],\n",
    "        [\"CD3+\", \"red\", (7, 4), (10, 4), (10, 1), (7.5, -1.5), (7, -1.5)],\n",
    "        [\"Granulocytes\", \"yellow\", (14, 7.5), (18, 10), (18, 0), (7, -15), (4, -5), (7, -1.5), (7.5, -1.5), (10, 1), (13, 5)],\n",
    "        [\"Trash\", \"black\", (-6, 22), (18, 22), (11, 10), (9, 5), (7, 4), (5, 3), \n",
    "        (3, -12), (-6, -12)],\n",
    "        [\"Trash\", \"black\", (12, -10), (18, -10), (18, -15), (12, -15)]\n",
    "    ],\n",
    "    subsample=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5b4c20-12e6-4709-906f-5a76b99860dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in types:\n",
    "    for j in samples:\n",
    "        res = umap_populations_plot(\n",
    "            path=path, dirs=dirs,\n",
    "            tube=\"xx_79a_45_Ki67_3_xx.fcs\",\n",
    "            sample_type=i,\n",
    "            sample_name=j,\n",
    "            polygons=[\n",
    "                [\"Plasma cells\", \"orange\", (11, 7.5), (12, 10), (14, 7.5), (13, 5), (11, 2.6), (10, 6), (10, 7)],\n",
    "                [\"Lymphocytes\", \"teal\", (7, 4), (10, 4), (10, 1), (7.5, -1.5), (7, -1.5)],\n",
    "                [\"Lymphocytes\", \"teal\", (9.5, 6), (10, 6), (10, 5), (9, 4.5)],\n",
    "                [\"CD79a+\", \"yellow\", (9.5, 6), (10, 6), (10, 5), (9, 4.5)],\n",
    "                [\"CD3+\", \"red\", (7, 4), (10, 4), (10, 1), (7.5, -1.5), (7, -1.5)],\n",
    "                [\"Granulocytes\", \"yellow\", (14, 7.5), (18, 10), (18, 0), (7, -15), (4, -5), (7, -1.5), (7.5, -1.5), (10, 1), (13, 5)],\n",
    "                [\"Trash\", \"black\", (-6, 22), (18, 22), (11, 10), (9, 5), (7, 4), (5, 3), \n",
    "                (3, -12), (-6, -12)],\n",
    "                [\"Trash\", \"black\", (12, -10), (18, -10), (18, -15), (12, -15)]\n",
    "            ],\n",
    "            subsample=1\n",
    "        )\n",
    "\n",
    "        print(i)\n",
    "        print(j)\n",
    "        if res is not None and not res.empty:\n",
    "            print(res.describe().T.tail(9).iloc[:, :2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3165d678-3bf2-4a8f-8eaf-8a06096f3507",
   "metadata": {},
   "source": [
    "# –ê–Ω–∞–ª–∏–∑ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf422de-33b7-4ae7-a548-61244381a100",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "process_test_data(path, tube, pdf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4420313b-662b-4a87-889b-1b00c6edeea5",
   "metadata": {},
   "source": [
    "# –û–±—Ä–∞—â–µ–Ω–∏–µ –∫ .csv-—Ñ–∞–π–ª—É –æ—Ç—á—ë—Ç–∞ –∏ –ø–µ—Ä–µ–∫–ª–∞–¥–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ –±–ª–∞–Ω–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd996125-7e75-46ab-ab76-865a75c80111",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "make_report(path,  # –ö–æ—Ä–Ω–µ–≤–∞—è –ø–∞–ø–∫–∞, –≤ –∫–æ—Ç–æ—Ä–æ–π –ª–µ–∂–∏—Ç –ø–∞–ø–∫–∞ Reports —Å –Ω–æ–≤—ã–º–∏ –æ—Ç—á—ë—Ç–∞–º–∏.\n",
    "            blanks=r'C:\\Users\\vsevo\\Downloads',  # –ü–∞–ø–∫–∞ —Å –∑–∞–∫–ª—é—á–µ–Ω–∏—è–º–∏ \n",
    "            coordinates=r'D:\\NovoExpress Data\\Examples\\Saved_UMAP_n_csv',  # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –¥–ª—è —Å–≤—è–∑–∏ —Ä–µ–ø–æ—Ä—Ç–∞ –∏ –±–ª–∞–Ω–∫–∞ –∑–∞–∫–ª—é—á–µ–Ω–∏—è\n",
    "            clean=False)  # –ï—Å–ª–∏ True (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é), –æ—Ç—á—ë—Ç–Ω—ã–µ —Ñ–∞–π–ª—ã –±—É–¥—É—Ç —É–ª–∞–¥–µ–Ω—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688980e9-59f7-49ef-b2bb-6ee65c2bbf9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
